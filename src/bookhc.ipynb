{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\henri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "c:\\Users\\henri\\miniconda3\\envs\\fake-news-env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import transformers as ppb # pytorch-pretrained-bert\n",
    "import torch\n",
    "\n",
    "import pipeline as pp\n",
    "import stats_hc as st\n",
    "import models as ml\n",
    "\n",
    "import importlib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 50081.24it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 182.42it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 9093.34it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 299.75it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 75.94it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2222.32it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1046.76it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]c:\\projects\\FakeNews\\FakeNews\\src\\stats_hc.py:98: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  def function_to_apply(self, row):\n",
      "100%|██████████| 100/100 [00:00<00:00, 255.84it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 100606.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish time: 2.829780101776123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pp)\n",
    "importlib.reload(st)\n",
    "stopwords_lst = stopwords.words('english')\n",
    "\n",
    "WordFreq = st.Word_frequency(labels=['fake', 'reliable'])\n",
    "Count_items = st.Count_items()\n",
    "Contribution = st.Contribution()\n",
    "Article_type_frequency = st.Article_type_frequency()\n",
    "\n",
    "pp.apply_pipeline(\n",
    "    \"../datasets/sample/dataset.csv\", \n",
    "    [   (pp.Binary_labels(), 'type', 'binary_label'),\n",
    "        (pp.Clean_data(), 'content'),\n",
    "        (pp.Tokenizer(), 'content'),\n",
    "        (pp.Remove_stopwords(stopwords_lst), 'content'),\n",
    "        (pp.Stem(), 'content'),\n",
    "        (WordFreq, None),\n",
    "        (Count_items, 'content'),\n",
    "        (Contribution, None),\n",
    "        (Article_type_frequency, 'type'),\n",
    "    ],\n",
    "    progress_bar=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WordFreq.plot_frequency(label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WordFreq.plot_fake_real(labels=('fake', 'reliable'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contribution.contributionPlot(threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Article_type_frequency.plot()\n",
    "Article_type_frequency.plotDistribution()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake-news-env",
   "language": "python",
   "name": "fake-news-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
