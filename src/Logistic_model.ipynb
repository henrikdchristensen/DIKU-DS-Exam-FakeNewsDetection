{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\madsv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import csr_matrix, vstack, load_npz, save_npz\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import transformers as ppb # pytorch-pretrained-bert\n",
    "import torch\n",
    "\n",
    "import pipeline as pp\n",
    "import models as ml\n",
    "import model_tests as mt\n",
    "\n",
    "import importlib\n",
    "import math\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproccessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covert types to binary labels - either True (reliable) or False (fake news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\madsv\\miniconda3\\envs\\penguin\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\madsv\\miniconda3\\envs\\penguin\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\madsv\\miniconda3\\envs\\penguin\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m importlib\u001b[39m.\u001b[39mreload(pp)\n\u001b[1;32m----> 3\u001b[0m pp\u001b[39m.\u001b[39;49mapply_pipeline(\n\u001b[0;32m      4\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m../datasets/big/combined_cleaned.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[0;32m      5\u001b[0m     [(pp\u001b[39m.\u001b[39;49mBinary_labels_LIAR(), \u001b[39m'\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtype_binary\u001b[39;49m\u001b[39m'\u001b[39;49m)], \n\u001b[0;32m      6\u001b[0m     new_file\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../datasets/big/combined_cleaned_bin.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[0;32m      7\u001b[0m     progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\madsv\\Documents\\Documents\\University\\DataScience\\FakeNews\\src\\pipeline.py:590\u001b[0m, in \u001b[0;36mapply_pipeline\u001b[1;34m(old_file, function_cols, new_file, batch_size, get_batch, progress_bar, nrows)\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[39mreturn\u001b[39;00m chunk\n\u001b[0;32m    589\u001b[0m \u001b[39m# Apply the specified functions to each row in the batch\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m chunk \u001b[39m=\u001b[39m applier(function_cols, chunk, progress_bar\u001b[39m=\u001b[39;49mprogress_bar)\n\u001b[0;32m    592\u001b[0m \u001b[39m# If an output file is specified, append the processed data to it\u001b[39;00m\n\u001b[0;32m    593\u001b[0m \u001b[39mif\u001b[39;00m new_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\madsv\\Documents\\Documents\\University\\DataScience\\FakeNews\\src\\pipeline.py:564\u001b[0m, in \u001b[0;36mapplier\u001b[1;34m(function_cols, chunk, progress_bar)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    563\u001b[0m     \u001b[39mif\u001b[39;00m progress_bar:\n\u001b[1;32m--> 564\u001b[0m         chunk[to_col] \u001b[39m=\u001b[39m chunk[from_col]\u001b[39m.\u001b[39mprogress_apply(function\u001b[39m.\u001b[39mfunction_to_apply)\n\u001b[0;32m    565\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    566\u001b[0m         chunk[to_col] \u001b[39m=\u001b[39m chunk[from_col]\u001b[39m.\u001b[39mapply(function\u001b[39m.\u001b[39mfunction_to_apply)\n",
      "File \u001b[1;32mc:\\Users\\madsv\\miniconda3\\envs\\penguin\\lib\\site-packages\\pandas\\core\\frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\madsv\\miniconda3\\envs\\penguin\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'type'"
     ]
    }
   ],
   "source": [
    "importlib.reload(pp)\n",
    "\n",
    "pp.apply_pipeline(\n",
    "    \"../datasets/big/combined_cleaned.csv\", \n",
    "    [(pp.Binary_labels_LIAR(), 'type', 'type_binary')], \n",
    "    new_file=\"../datasets/big/combined_cleaned_bin.csv\", \n",
    "    progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pp)\n",
    "\n",
    "pp.apply_pipeline(\n",
    "    \"../datasets/big/dataset.csv\", \n",
    "    [(pp.Binary_labels(), 'type', 'type_binary')], \n",
    "    new_file=\"../datasets/big/dataset_bin.csv\", \n",
    "    progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete nans\n",
    "pp.apply_pipeline(\n",
    "    \"../datasets/sample/dataset_unbalanced_1M.csv\",\n",
    "    [(pp.Delete_nan(), 'content_title'),\n",
    "     (pp.Delete_nan(), 'content_domain'),\n",
    "     (pp.Delete_nan(), 'content_authors'),\n",
    "     (pp.Delete_nan(), 'content_domain_authors_title')],\n",
    "     new_file=\"../datasets/sample/dataset_unbalanced_1M_.csv\",\n",
    "     progress_bar=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the follwoing input files:\n",
    "* All are unbalanced\n",
    "* The test and validation set are balanced according to the types (e.g. satire, reliable...), and the test set is unbalanced\n",
    "* The test and validation set are balanced according to the binary classes, and the test set is unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of rows to train the model\n",
    "BATCH_SIZE = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pp)\n",
    "from_file = \"../datasets/big/dataset_bin.csv\"\n",
    "\n",
    "pp.get_dataframe_with_distribution(from_file, BATCH_SIZE, [0.8,0.1,0.1], [False, False, False], \n",
    "                                    out_file=\"../datasets/sample/dataset_unbalanced_1M.csv\", get_frame=False)\n",
    "#pp.get_dataframe_with_distribution(from_file, BATCH_SIZE, [0.5 ,0.1,0.1], [True, False, False], \n",
    "#                                    out_file=\"../datasets/sample/dataset_balanced_types.csv\", get_frame=False)\n",
    "#pp.get_dataframe_with_distribution(from_file, BATCH_SIZE, [0.8,0.1,0.1], [True, False, False],\n",
    "#                                    out_file=\"../datasets/sample/dataset_balanced_bin.csv\", get_frame=False, classes=[True,False], type_col=\"type_binary\")\n",
    "#pp.get_dataframe_with_distribution(from_file, BATCH_SIZE, [0.8,0.1,0.1], [True, False, False], \n",
    "#                                    out_file=\"../datasets/sample/dataset_balanced_reliable_fake.csv\", get_frame=False, classes=[\"reliable\", \"fake\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution of labels (just to show that everything works)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 768849.38it/s]\n",
      "100%|██████████| 10000/10000 [00:18<00:00, 539.50it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 18019.53it/s]\n",
      "100%|██████████| 10000/10000 [00:08<00:00, 1205.96it/s]\n",
      "100%|██████████| 10000/10000 [01:02<00:00, 161.14it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 82612.20it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 169198.84it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 15205.85it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 124929.01it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 51255.62it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 6579.82it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 497940.71it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 167259.01it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 38457.73it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 37036.88it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 37947.78it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 26879.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 200000 rows\n",
      "finish time: 97.20679092407227\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pp)\n",
    "\n",
    "def Clean_data(file, new_file):\n",
    "    stopwords_lst = stopwords.words('english')\n",
    "    pp.apply_pipeline(file, [\n",
    "            # binary labels\n",
    "            (pp.Binary_labels(), 'type', 'type_binary'),\n",
    "            # Clean content\n",
    "            (pp.Clean_data(), 'content'),\n",
    "            (pp.Tokenizer(), \"content\"),\n",
    "            (pp.Remove_stopwords(stopwords_lst), \"content\"),\n",
    "            (pp.Stem(), \"content\"),\n",
    "            (pp.Combine_Content(), \"content\", \"content_combined\"),\n",
    "            # Clean authors\n",
    "            (pp.Clean_author(), \"authors\"),\n",
    "            # Clean title\n",
    "            (pp.Clean_data(), 'title'),\n",
    "            (pp.Tokenizer(), \"title\"),\n",
    "            (pp.Remove_stopwords(stopwords_lst), \"title\"),\n",
    "            (pp.Stem(), \"title\"),\n",
    "            (pp.Combine_Content(), \"title\"),\n",
    "            # Clean domain\n",
    "            (pp.Clean_domain(), 'domain'),\n",
    "            # Combine columns (used as features)\n",
    "            (pp.Join_str_columns([\"content_combined\", \"authors\"]), None, \"content_authors\"),\n",
    "            (pp.Join_str_columns([\"content_combined\", \"title\"]), None, \"content_title\"),\n",
    "            (pp.Join_str_columns([\"content_combined\", \"domain\"]), None, \"content_domain\"),\n",
    "            (pp.Join_str_columns([\"content_combined\", \"domain\", \"authors\", \"title\"]), None, \"content_domain_authors_title\")\n",
    "        ],\n",
    "        new_file=new_file,\n",
    "        progress_bar=True,\n",
    "    )\n",
    "\n",
    "#Clean_data(\"../datasets/sample/dataset_unbalanced.csv\", \"../datasets/sample/dataset_unbalanced_cleaned.csv\")\n",
    "#Clean_data(\"../datasets/sample/dataset_balanced_types.csv\", \"../datasets/sample/dataset_balanced_types_cleaned.csv\")\n",
    "#Clean_data(\"../datasets/sample/dataset_balanced_bin.csv\", \"../datasets/sample/dataset_balanced_bin_cleaned.csv\")\n",
    "Clean_data(\"../datasets/sample/dataset_reliable_fake.csv\", \"../datasets/sample/dataset_reliable_fake_cleaned.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the logistic model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting liar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_data = pd.read_csv(\"../datasets/big/combined_cleaned_bin.csv\")\n",
    "X_liar =  liar_data[\"statement_combined\"].values\n",
    "y_liar = liar_data[\"type_binary\"].astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing models (other than logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive_bayes finished in 3.49 seconds\n",
      "random_forest finished in 129.19 seconds\n",
      "decision_tree finished in 56.97 seconds\n",
      "ada_boost finished in 64.29 seconds\n",
      "passive_aggressive finished in 105.30 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>split</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>acc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>passive_aggressive</td>\n",
       "      <td>val</td>\n",
       "      <td>0.897184</td>\n",
       "      <td>0.849520</td>\n",
       "      <td>0.831041</td>\n",
       "      <td>0.892127</td>\n",
       "      <td>0.860501</td>\n",
       "      <td>104.06</td>\n",
       "      <td>[[38540, 9436], [5612, 46412]]</td>\n",
       "      <td>PassiveAggressiveClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>val</td>\n",
       "      <td>0.817462</td>\n",
       "      <td>0.805740</td>\n",
       "      <td>0.816596</td>\n",
       "      <td>0.808089</td>\n",
       "      <td>0.812320</td>\n",
       "      <td>1.28</td>\n",
       "      <td>[[38534, 9442], [9984, 42040]]</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>val</td>\n",
       "      <td>0.686635</td>\n",
       "      <td>0.686450</td>\n",
       "      <td>0.662730</td>\n",
       "      <td>0.809011</td>\n",
       "      <td>0.728601</td>\n",
       "      <td>36.01</td>\n",
       "      <td>[[26557, 21419], [9936, 42088]]</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=5, max_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>val</td>\n",
       "      <td>0.653153</td>\n",
       "      <td>0.653150</td>\n",
       "      <td>0.818252</td>\n",
       "      <td>0.428456</td>\n",
       "      <td>0.562417</td>\n",
       "      <td>55.09</td>\n",
       "      <td>[[43025, 4951], [29734, 22290]]</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ada_boost</td>\n",
       "      <td>val</td>\n",
       "      <td>0.653153</td>\n",
       "      <td>0.653150</td>\n",
       "      <td>0.818252</td>\n",
       "      <td>0.428456</td>\n",
       "      <td>0.562417</td>\n",
       "      <td>60.94</td>\n",
       "      <td>[[43025, 4951], [29734, 22290]]</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>passive_aggressive</td>\n",
       "      <td>test</td>\n",
       "      <td>0.897184</td>\n",
       "      <td>0.848720</td>\n",
       "      <td>0.831731</td>\n",
       "      <td>0.892052</td>\n",
       "      <td>0.860836</td>\n",
       "      <td>104.06</td>\n",
       "      <td>[[38083, 9466], [5662, 46789]]</td>\n",
       "      <td>PassiveAggressiveClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>test</td>\n",
       "      <td>0.817462</td>\n",
       "      <td>0.807920</td>\n",
       "      <td>0.821667</td>\n",
       "      <td>0.809479</td>\n",
       "      <td>0.815528</td>\n",
       "      <td>1.28</td>\n",
       "      <td>[[38334, 9215], [9993, 42458]]</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>test</td>\n",
       "      <td>0.686635</td>\n",
       "      <td>0.688660</td>\n",
       "      <td>0.667022</td>\n",
       "      <td>0.811538</td>\n",
       "      <td>0.732218</td>\n",
       "      <td>36.01</td>\n",
       "      <td>[[26300, 21249], [9885, 42566]]</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=5, max_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>test</td>\n",
       "      <td>0.653153</td>\n",
       "      <td>0.652750</td>\n",
       "      <td>0.821077</td>\n",
       "      <td>0.432118</td>\n",
       "      <td>0.566236</td>\n",
       "      <td>55.09</td>\n",
       "      <td>[[42610, 4939], [29786, 22665]]</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ada_boost</td>\n",
       "      <td>test</td>\n",
       "      <td>0.653153</td>\n",
       "      <td>0.652750</td>\n",
       "      <td>0.821077</td>\n",
       "      <td>0.432118</td>\n",
       "      <td>0.566236</td>\n",
       "      <td>60.94</td>\n",
       "      <td>[[42610, 4939], [29786, 22665]]</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.817462</td>\n",
       "      <td>0.529435</td>\n",
       "      <td>0.561704</td>\n",
       "      <td>0.711382</td>\n",
       "      <td>0.627744</td>\n",
       "      <td>1.28</td>\n",
       "      <td>[[1697, 3960], [2059, 5075]]</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>passive_aggressive</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.897184</td>\n",
       "      <td>0.490032</td>\n",
       "      <td>0.577010</td>\n",
       "      <td>0.320858</td>\n",
       "      <td>0.412395</td>\n",
       "      <td>104.06</td>\n",
       "      <td>[[3979, 1678], [4845, 2289]]</td>\n",
       "      <td>PassiveAggressiveClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.653153</td>\n",
       "      <td>0.444062</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>0.017682</td>\n",
       "      <td>55.09</td>\n",
       "      <td>[[5616, 41], [7070, 64]]</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ada_boost</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.653153</td>\n",
       "      <td>0.444062</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>0.017682</td>\n",
       "      <td>60.94</td>\n",
       "      <td>[[5616, 41], [7070, 64]]</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.686635</td>\n",
       "      <td>0.443984</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.006728</td>\n",
       "      <td>0.013319</td>\n",
       "      <td>36.01</td>\n",
       "      <td>[[5631, 26], [7086, 48]]</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=5, max_featu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name split  train_acc       acc  precision    recall  \\\n",
       "0  passive_aggressive   val   0.897184  0.849520   0.831041  0.892127   \n",
       "0         naive_bayes   val   0.817462  0.805740   0.816596  0.808089   \n",
       "0       random_forest   val   0.686635  0.686450   0.662730  0.809011   \n",
       "0       decision_tree   val   0.653153  0.653150   0.818252  0.428456   \n",
       "0           ada_boost   val   0.653153  0.653150   0.818252  0.428456   \n",
       "1  passive_aggressive  test   0.897184  0.848720   0.831731  0.892052   \n",
       "1         naive_bayes  test   0.817462  0.807920   0.821667  0.809479   \n",
       "1       random_forest  test   0.686635  0.688660   0.667022  0.811538   \n",
       "1       decision_tree  test   0.653153  0.652750   0.821077  0.432118   \n",
       "1           ada_boost  test   0.653153  0.652750   0.821077  0.432118   \n",
       "2         naive_bayes  liar   0.817462  0.529435   0.561704  0.711382   \n",
       "2  passive_aggressive  liar   0.897184  0.490032   0.577010  0.320858   \n",
       "2       decision_tree  liar   0.653153  0.444062   0.609524  0.008971   \n",
       "2           ada_boost  liar   0.653153  0.444062   0.609524  0.008971   \n",
       "2       random_forest  liar   0.686635  0.443984   0.648649  0.006728   \n",
       "\n",
       "         f1    time                 confusion_matrix  \\\n",
       "0  0.860501  104.06   [[38540, 9436], [5612, 46412]]   \n",
       "0  0.812320    1.28   [[38534, 9442], [9984, 42040]]   \n",
       "0  0.728601   36.01  [[26557, 21419], [9936, 42088]]   \n",
       "0  0.562417   55.09  [[43025, 4951], [29734, 22290]]   \n",
       "0  0.562417   60.94  [[43025, 4951], [29734, 22290]]   \n",
       "1  0.860836  104.06   [[38083, 9466], [5662, 46789]]   \n",
       "1  0.815528    1.28   [[38334, 9215], [9993, 42458]]   \n",
       "1  0.732218   36.01  [[26300, 21249], [9885, 42566]]   \n",
       "1  0.566236   55.09  [[42610, 4939], [29786, 22665]]   \n",
       "1  0.566236   60.94  [[42610, 4939], [29786, 22665]]   \n",
       "2  0.627744    1.28     [[1697, 3960], [2059, 5075]]   \n",
       "2  0.412395  104.06     [[3979, 1678], [4845, 2289]]   \n",
       "2  0.017682   55.09         [[5616, 41], [7070, 64]]   \n",
       "2  0.017682   60.94         [[5616, 41], [7070, 64]]   \n",
       "2  0.013319   36.01         [[5631, 26], [7086, 48]]   \n",
       "\n",
       "                                               model  \n",
       "0                      PassiveAggressiveClassifier()  \n",
       "0                                    MultinomialNB()  \n",
       "0  (DecisionTreeClassifier(max_depth=5, max_featu...  \n",
       "0                DecisionTreeClassifier(max_depth=2)  \n",
       "0  (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "1                      PassiveAggressiveClassifier()  \n",
       "1                                    MultinomialNB()  \n",
       "1  (DecisionTreeClassifier(max_depth=5, max_featu...  \n",
       "1                DecisionTreeClassifier(max_depth=2)  \n",
       "1  (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "2                                    MultinomialNB()  \n",
       "2                      PassiveAggressiveClassifier()  \n",
       "2                DecisionTreeClassifier(max_depth=2)  \n",
       "2  (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "2  (DecisionTreeClassifier(max_depth=5, max_featu...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "info_list = [(\n",
    "    \"../datasets/sample/dataset_unbalanced_1M.csv\", \"content_combined\", mt.create_count_vector, [\n",
    "        (MultinomialNB(), \"naive_bayes\"),\n",
    "        (RandomForestClassifier(max_depth=5), \"random_forest\"), #25\n",
    "        (DecisionTreeClassifier(max_depth=2), \"decision_tree\"),\n",
    "        (AdaBoostClassifier(n_estimators=2), \"ada_boost\"), #2\n",
    "        #(SVC(kernel='linear', max_iter=10), \"svm\"),\n",
    "        #(KNeighborsClassifier(n_neighbors=2, algorithm='kd_tree'), \"knn\"), #15\n",
    "        (PassiveAggressiveClassifier(), \"passive_aggressive\")\n",
    "        ])\n",
    "]\n",
    "\n",
    "test_stats_base = mt.Test_statistic()\n",
    "\n",
    "#mt.create_vectors_from_infolist(\"../datasets/sample/dataset_count_vectors_100K.pickle\", info_list, X_liar, y_liar)\n",
    "mt.test_vectors_from_infolist(\"../datasets/sample/dataset_count_vectors.pickle\", info_list, tests=test_stats_base)\n",
    "test_stats_base.metrics.sort_values(by=[\"split\",\"f1\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vector 0 (data read in 102.84065556526184 seconds)\n",
      "Saved vector 0 in 404.05762100219727 seconds\n",
      "content_count finished in 372.46 seconds\n",
      "content_count_hyper finished in 358.35 seconds\n",
      "content_count_hyper finished in 363.09 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>split</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>acc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content_count_hyper</td>\n",
       "      <td>val</td>\n",
       "      <td>0.897783</td>\n",
       "      <td>0.873580</td>\n",
       "      <td>0.892032</td>\n",
       "      <td>0.861237</td>\n",
       "      <td>0.876364</td>\n",
       "      <td>357.04</td>\n",
       "      <td>[[42553, 5423], [7219, 44805]]</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content_count</td>\n",
       "      <td>val</td>\n",
       "      <td>0.900499</td>\n",
       "      <td>0.872150</td>\n",
       "      <td>0.891333</td>\n",
       "      <td>0.858969</td>\n",
       "      <td>0.874852</td>\n",
       "      <td>370.91</td>\n",
       "      <td>[[42528, 5448], [7337, 44687]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content_count_hyper</td>\n",
       "      <td>val</td>\n",
       "      <td>0.899829</td>\n",
       "      <td>0.870950</td>\n",
       "      <td>0.889639</td>\n",
       "      <td>0.858431</td>\n",
       "      <td>0.873756</td>\n",
       "      <td>361.62</td>\n",
       "      <td>[[42436, 5540], [7365, 44659]]</td>\n",
       "      <td>LogisticRegression(C=250, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content_count_hyper</td>\n",
       "      <td>test</td>\n",
       "      <td>0.897783</td>\n",
       "      <td>0.871240</td>\n",
       "      <td>0.890248</td>\n",
       "      <td>0.860613</td>\n",
       "      <td>0.875179</td>\n",
       "      <td>357.04</td>\n",
       "      <td>[[41984, 5565], [7311, 45140]]</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content_count_hyper</td>\n",
       "      <td>test</td>\n",
       "      <td>0.899829</td>\n",
       "      <td>0.870400</td>\n",
       "      <td>0.888821</td>\n",
       "      <td>0.860556</td>\n",
       "      <td>0.874460</td>\n",
       "      <td>361.62</td>\n",
       "      <td>[[41903, 5646], [7314, 45137]]</td>\n",
       "      <td>LogisticRegression(C=250, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content_count</td>\n",
       "      <td>test</td>\n",
       "      <td>0.900499</td>\n",
       "      <td>0.870110</td>\n",
       "      <td>0.889033</td>\n",
       "      <td>0.859659</td>\n",
       "      <td>0.874100</td>\n",
       "      <td>370.91</td>\n",
       "      <td>[[41921, 5628], [7361, 45090]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content_count_hyper</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.899829</td>\n",
       "      <td>0.477132</td>\n",
       "      <td>0.586167</td>\n",
       "      <td>0.212644</td>\n",
       "      <td>0.312076</td>\n",
       "      <td>361.62</td>\n",
       "      <td>[[4586, 1071], [5617, 1517]]</td>\n",
       "      <td>LogisticRegression(C=250, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content_count</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.900499</td>\n",
       "      <td>0.475881</td>\n",
       "      <td>0.582692</td>\n",
       "      <td>0.212363</td>\n",
       "      <td>0.311280</td>\n",
       "      <td>370.91</td>\n",
       "      <td>[[4572, 1085], [5619, 1515]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content_count_hyper</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.897783</td>\n",
       "      <td>0.473849</td>\n",
       "      <td>0.583540</td>\n",
       "      <td>0.197785</td>\n",
       "      <td>0.295436</td>\n",
       "      <td>357.04</td>\n",
       "      <td>[[4650, 1007], [5723, 1411]]</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=300)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name split  train_acc       acc  precision    recall  \\\n",
       "0  content_count_hyper   val   0.897783  0.873580   0.892032  0.861237   \n",
       "0        content_count   val   0.900499  0.872150   0.891333  0.858969   \n",
       "0  content_count_hyper   val   0.899829  0.870950   0.889639  0.858431   \n",
       "1  content_count_hyper  test   0.897783  0.871240   0.890248  0.860613   \n",
       "1  content_count_hyper  test   0.899829  0.870400   0.888821  0.860556   \n",
       "1        content_count  test   0.900499  0.870110   0.889033  0.859659   \n",
       "2  content_count_hyper  liar   0.899829  0.477132   0.586167  0.212644   \n",
       "2        content_count  liar   0.900499  0.475881   0.582692  0.212363   \n",
       "2  content_count_hyper  liar   0.897783  0.473849   0.583540  0.197785   \n",
       "\n",
       "         f1    time                confusion_matrix  \\\n",
       "0  0.876364  357.04  [[42553, 5423], [7219, 44805]]   \n",
       "0  0.874852  370.91  [[42528, 5448], [7337, 44687]]   \n",
       "0  0.873756  361.62  [[42436, 5540], [7365, 44659]]   \n",
       "1  0.875179  357.04  [[41984, 5565], [7311, 45140]]   \n",
       "1  0.874460  361.62  [[41903, 5646], [7314, 45137]]   \n",
       "1  0.874100  370.91  [[41921, 5628], [7361, 45090]]   \n",
       "2  0.312076  361.62    [[4586, 1071], [5617, 1517]]   \n",
       "2  0.311280  370.91    [[4572, 1085], [5619, 1515]]   \n",
       "2  0.295436  357.04    [[4650, 1007], [5723, 1411]]   \n",
       "\n",
       "                                     model  \n",
       "0  LogisticRegression(C=0.1, max_iter=300)  \n",
       "0         LogisticRegression(max_iter=300)  \n",
       "0  LogisticRegression(C=250, max_iter=300)  \n",
       "1  LogisticRegression(C=0.1, max_iter=300)  \n",
       "1  LogisticRegression(C=250, max_iter=300)  \n",
       "1         LogisticRegression(max_iter=300)  \n",
       "2  LogisticRegression(C=250, max_iter=300)  \n",
       "2         LogisticRegression(max_iter=300)  \n",
       "2  LogisticRegression(C=0.1, max_iter=300)  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FINISHED\n",
    "importlib.reload(mt)\n",
    "\n",
    "unbalanced = \"../datasets/sample/dataset_unbalanced_1M.csv\"\n",
    "balanced_types = \"../datasets/sample/dataset_balanced_types_1M.csv\"\n",
    "balanced_bin = \"../datasets/sample/dataset_balanced_bin_1M.csv\"\n",
    "balanced_reliable_fake = \"../datasets/sample/dataset_balanced_reliable_fake_1M.csv\"\n",
    "\n",
    "info_list = [\n",
    "    (unbalanced, \"content_combined\", mt.create_count_vector, [(LogisticRegression(max_iter=300), \"content_count\"), \n",
    "                                                              (LogisticRegression(max_iter=300, C=0.1), \"content_count_hyper\"),\n",
    "                                                              (LogisticRegression(max_iter=300, C=250), \"content_count_hyper\")]),\n",
    "    #(balanced_types, \"content_combined\", mt.create_count_vector, [(LogisticRegression(max_iter=300), \"content_count_balanced_types\")]),\n",
    "    #(balanced_bin, \"content_combined\", mt.create_count_vector, [(LogisticRegression(max_iter=300), \"content_count_balanced_bin\")]),\n",
    "    #(balanced_reliable_fake, \"content_combined\", mt.create_count_vector, [(LogisticRegression(max_iter=300), \"content_count_reliable_fake\")]),\n",
    "]\n",
    "\n",
    "test_stats_simple = mt.Test_statistic()\n",
    "\n",
    "mt.create_vectors_from_infolist(\"../datasets/sample/dataset_count_vectors.pickle\", info_list, X_liar, y_liar)\n",
    "mt.test_vectors_from_infolist(\"../datasets/sample/dataset_count_vectors.pickle\", info_list, tests=test_stats_simple)\n",
    "test_stats_simple.metrics.sort_values(by=[\"split\",\"f1\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(mt)\n",
    "\n",
    "unbalanced = \"../datasets/sample/dataset_unbalanced_1M.csv\"\n",
    "\n",
    "info_list = [\n",
    "    \n",
    "     (unbalanced, \"content_combined\", mt.create_tdfidf_vector_unigram, [(LogisticRegression(max_iter=300), \"content_tfidf\")]),\n",
    "                                                                        (LogisticRegression(max_iter=300, C=250), \"content_tfidf_hyper_1\"),\n",
    "                                                                        (LogisticRegression(max_iter=300, C=0.1), \"content_tfidf_hyper_2\")]),\n",
    "]\n",
    "\n",
    "test_stats_tdidf = mt.Test_statistic()\n",
    "\n",
    "mt.create_vectors_from_infolist(\"../datasets/sample/dataset_tdidf_vectors.pickle\", info_list, X_liar, y_liar)\n",
    "mt.test_vectors_from_infolist(\"../datasets/sample/dataset_tdidf_vectors.pickle\", info_list, tests=test_stats_tdidf)\n",
    "test_stats_tdidf.metrics.sort_values(by=[\"split\",\"f1\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vector 0 (data read in 1.3838915824890137 seconds)\n",
      "Saved vector 0 in 4.555252313613892 seconds\n",
      "Creating vector 1 (data read in 1.1119475364685059 seconds)\n",
      "Saved vector 1 in 15.999372720718384 seconds\n",
      "Creating vector 2 (data read in 1.0411128997802734 seconds)\n",
      "Saved vector 2 in 117.24633693695068 seconds\n",
      "content_tfidf_bi finished in 0.62 seconds\n",
      "content_tfidf_bi_hyper_1 finished in 3.26 seconds\n",
      "content_tfidf_bi_hyper_2 finished in 0.34 seconds\n",
      "content_tfidf_bi finished in 7.79 seconds\n",
      "content_tfidf_bi_hyper_1 finished in 34.92 seconds\n",
      "content_tfidf_bi_hyper_2 finished in 7.24 seconds\n",
      "content_tfidf_tri finished in 15.85 seconds\n",
      "content_tfidf_tri_hyper_1 finished in 35.05 seconds\n",
      "content_tfidf_hyper_2 finished in 12.46 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>split</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>acc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content_tfidf_bi_hyper_1</td>\n",
       "      <td>val</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847000</td>\n",
       "      <td>0.838475</td>\n",
       "      <td>0.878327</td>\n",
       "      <td>0.857939</td>\n",
       "      <td>34.86</td>\n",
       "      <td>[[385, 89], [64, 462]]</td>\n",
       "      <td>LogisticRegression(C=250, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content_tfidf_tri_hyper_1</td>\n",
       "      <td>val</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.818339</td>\n",
       "      <td>0.899240</td>\n",
       "      <td>0.856884</td>\n",
       "      <td>34.98</td>\n",
       "      <td>[[369, 105], [53, 473]]</td>\n",
       "      <td>LogisticRegression(C=250, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content_tfidf_bi</td>\n",
       "      <td>val</td>\n",
       "      <td>0.965250</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.815603</td>\n",
       "      <td>0.874525</td>\n",
       "      <td>0.844037</td>\n",
       "      <td>7.72</td>\n",
       "      <td>[[370, 104], [66, 460]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content_tfidf_tri</td>\n",
       "      <td>val</td>\n",
       "      <td>0.978250</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.805217</td>\n",
       "      <td>0.880228</td>\n",
       "      <td>0.841054</td>\n",
       "      <td>15.78</td>\n",
       "      <td>[[362, 112], [63, 463]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content_tfidf_bi</td>\n",
       "      <td>val</td>\n",
       "      <td>0.919375</td>\n",
       "      <td>0.823000</td>\n",
       "      <td>0.822551</td>\n",
       "      <td>0.846008</td>\n",
       "      <td>0.834114</td>\n",
       "      <td>0.58</td>\n",
       "      <td>[[378, 96], [81, 445]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content_tfidf_bi_hyper_2</td>\n",
       "      <td>val</td>\n",
       "      <td>0.874250</td>\n",
       "      <td>0.797000</td>\n",
       "      <td>0.753532</td>\n",
       "      <td>0.912548</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>7.16</td>\n",
       "      <td>[[317, 157], [46, 480]]</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content_tfidf_hyper_2</td>\n",
       "      <td>val</td>\n",
       "      <td>0.886500</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.722063</td>\n",
       "      <td>0.958175</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>12.39</td>\n",
       "      <td>[[280, 194], [22, 504]]</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content_tfidf_bi_hyper_1</td>\n",
       "      <td>val</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.836502</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>3.23</td>\n",
       "      <td>[[370, 104], [86, 440]]</td>\n",
       "      <td>LogisticRegression(C=250, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content_tfidf_bi_hyper_2</td>\n",
       "      <td>val</td>\n",
       "      <td>0.838500</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>0.767361</td>\n",
       "      <td>0.840304</td>\n",
       "      <td>0.802178</td>\n",
       "      <td>0.30</td>\n",
       "      <td>[[340, 134], [84, 442]]</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content_tfidf_tri_hyper_1</td>\n",
       "      <td>test</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833000</td>\n",
       "      <td>0.803309</td>\n",
       "      <td>0.879276</td>\n",
       "      <td>0.839577</td>\n",
       "      <td>34.98</td>\n",
       "      <td>[[396, 107], [60, 437]]</td>\n",
       "      <td>LogisticRegression(C=250, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content_tfidf_bi_hyper_1</td>\n",
       "      <td>test</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.820809</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.838583</td>\n",
       "      <td>34.86</td>\n",
       "      <td>[[410, 93], [71, 426]]</td>\n",
       "      <td>LogisticRegression(C=250, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content_tfidf_tri</td>\n",
       "      <td>test</td>\n",
       "      <td>0.978250</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.781528</td>\n",
       "      <td>0.885312</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>15.78</td>\n",
       "      <td>[[380, 123], [57, 440]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content_tfidf_bi</td>\n",
       "      <td>test</td>\n",
       "      <td>0.919375</td>\n",
       "      <td>0.828000</td>\n",
       "      <td>0.816764</td>\n",
       "      <td>0.843058</td>\n",
       "      <td>0.829703</td>\n",
       "      <td>0.58</td>\n",
       "      <td>[[409, 94], [78, 419]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content_tfidf_bi</td>\n",
       "      <td>test</td>\n",
       "      <td>0.965250</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>0.794824</td>\n",
       "      <td>0.865191</td>\n",
       "      <td>0.828516</td>\n",
       "      <td>7.72</td>\n",
       "      <td>[[392, 111], [67, 430]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content_tfidf_bi_hyper_1</td>\n",
       "      <td>test</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.804391</td>\n",
       "      <td>0.810865</td>\n",
       "      <td>0.807615</td>\n",
       "      <td>3.23</td>\n",
       "      <td>[[405, 98], [94, 403]]</td>\n",
       "      <td>LogisticRegression(C=250, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content_tfidf_bi_hyper_2</td>\n",
       "      <td>test</td>\n",
       "      <td>0.838500</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>[[370, 133], [77, 420]]</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content_tfidf_bi_hyper_2</td>\n",
       "      <td>test</td>\n",
       "      <td>0.874250</td>\n",
       "      <td>0.777000</td>\n",
       "      <td>0.722403</td>\n",
       "      <td>0.895372</td>\n",
       "      <td>0.799641</td>\n",
       "      <td>7.16</td>\n",
       "      <td>[[332, 171], [52, 445]]</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content_tfidf_hyper_2</td>\n",
       "      <td>test</td>\n",
       "      <td>0.886500</td>\n",
       "      <td>0.762000</td>\n",
       "      <td>0.692996</td>\n",
       "      <td>0.935614</td>\n",
       "      <td>0.796233</td>\n",
       "      <td>12.39</td>\n",
       "      <td>[[297, 206], [32, 465]]</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content_tfidf_hyper_2</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.886500</td>\n",
       "      <td>0.556954</td>\n",
       "      <td>0.571317</td>\n",
       "      <td>0.823661</td>\n",
       "      <td>0.674666</td>\n",
       "      <td>12.39</td>\n",
       "      <td>[[1248, 4409], [1258, 5876]]</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content_tfidf_tri</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.978250</td>\n",
       "      <td>0.549292</td>\n",
       "      <td>0.583020</td>\n",
       "      <td>0.673816</td>\n",
       "      <td>0.625138</td>\n",
       "      <td>15.78</td>\n",
       "      <td>[[2219, 3438], [2327, 4807]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content_tfidf_bi_hyper_2</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.874250</td>\n",
       "      <td>0.547182</td>\n",
       "      <td>0.583624</td>\n",
       "      <td>0.656434</td>\n",
       "      <td>0.617892</td>\n",
       "      <td>7.16</td>\n",
       "      <td>[[2316, 3341], [2451, 4683]]</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content_tfidf_bi</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.965250</td>\n",
       "      <td>0.542647</td>\n",
       "      <td>0.588699</td>\n",
       "      <td>0.597281</td>\n",
       "      <td>0.592959</td>\n",
       "      <td>7.72</td>\n",
       "      <td>[[2680, 2977], [2873, 4261]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content_tfidf_bi_hyper_2</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.838500</td>\n",
       "      <td>0.541005</td>\n",
       "      <td>0.592991</td>\n",
       "      <td>0.564480</td>\n",
       "      <td>0.578384</td>\n",
       "      <td>0.30</td>\n",
       "      <td>[[2893, 2764], [3107, 4027]]</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content_tfidf_bi</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.919375</td>\n",
       "      <td>0.539833</td>\n",
       "      <td>0.592747</td>\n",
       "      <td>0.559013</td>\n",
       "      <td>0.575386</td>\n",
       "      <td>0.58</td>\n",
       "      <td>[[2917, 2740], [3146, 3988]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content_tfidf_tri_hyper_1</td>\n",
       "      <td>liar</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528028</td>\n",
       "      <td>0.592982</td>\n",
       "      <td>0.490328</td>\n",
       "      <td>0.536791</td>\n",
       "      <td>34.98</td>\n",
       "      <td>[[3256, 2401], [3636, 3498]]</td>\n",
       "      <td>LogisticRegression(C=250, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content_tfidf_bi_hyper_1</td>\n",
       "      <td>liar</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.520522</td>\n",
       "      <td>0.588101</td>\n",
       "      <td>0.468321</td>\n",
       "      <td>0.521420</td>\n",
       "      <td>3.23</td>\n",
       "      <td>[[3317, 2340], [3793, 3341]]</td>\n",
       "      <td>LogisticRegression(C=250, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content_tfidf_bi_hyper_1</td>\n",
       "      <td>liar</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.523728</td>\n",
       "      <td>0.602317</td>\n",
       "      <td>0.429913</td>\n",
       "      <td>0.501718</td>\n",
       "      <td>34.86</td>\n",
       "      <td>[[3632, 2025], [4067, 3067]]</td>\n",
       "      <td>LogisticRegression(C=250, max_iter=300)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name split  train_acc       acc  precision    recall  \\\n",
       "0   content_tfidf_bi_hyper_1   val   1.000000  0.847000   0.838475  0.878327   \n",
       "0  content_tfidf_tri_hyper_1   val   1.000000  0.842000   0.818339  0.899240   \n",
       "0           content_tfidf_bi   val   0.965250  0.830000   0.815603  0.874525   \n",
       "0          content_tfidf_tri   val   0.978250  0.825000   0.805217  0.880228   \n",
       "0           content_tfidf_bi   val   0.919375  0.823000   0.822551  0.846008   \n",
       "0   content_tfidf_bi_hyper_2   val   0.874250  0.797000   0.753532  0.912548   \n",
       "0      content_tfidf_hyper_2   val   0.886500  0.784000   0.722063  0.958175   \n",
       "0   content_tfidf_bi_hyper_1   val   1.000000  0.810000   0.808824  0.836502   \n",
       "0   content_tfidf_bi_hyper_2   val   0.838500  0.782000   0.767361  0.840304   \n",
       "1  content_tfidf_tri_hyper_1  test   1.000000  0.833000   0.803309  0.879276   \n",
       "1   content_tfidf_bi_hyper_1  test   1.000000  0.836000   0.820809  0.857143   \n",
       "1          content_tfidf_tri  test   0.978250  0.820000   0.781528  0.885312   \n",
       "1           content_tfidf_bi  test   0.919375  0.828000   0.816764  0.843058   \n",
       "1           content_tfidf_bi  test   0.965250  0.822000   0.794824  0.865191   \n",
       "1   content_tfidf_bi_hyper_1  test   1.000000  0.808000   0.804391  0.810865   \n",
       "1   content_tfidf_bi_hyper_2  test   0.838500  0.790000   0.759494  0.845070   \n",
       "1   content_tfidf_bi_hyper_2  test   0.874250  0.777000   0.722403  0.895372   \n",
       "1      content_tfidf_hyper_2  test   0.886500  0.762000   0.692996  0.935614   \n",
       "2      content_tfidf_hyper_2  liar   0.886500  0.556954   0.571317  0.823661   \n",
       "2          content_tfidf_tri  liar   0.978250  0.549292   0.583020  0.673816   \n",
       "2   content_tfidf_bi_hyper_2  liar   0.874250  0.547182   0.583624  0.656434   \n",
       "2           content_tfidf_bi  liar   0.965250  0.542647   0.588699  0.597281   \n",
       "2   content_tfidf_bi_hyper_2  liar   0.838500  0.541005   0.592991  0.564480   \n",
       "2           content_tfidf_bi  liar   0.919375  0.539833   0.592747  0.559013   \n",
       "2  content_tfidf_tri_hyper_1  liar   1.000000  0.528028   0.592982  0.490328   \n",
       "2   content_tfidf_bi_hyper_1  liar   1.000000  0.520522   0.588101  0.468321   \n",
       "2   content_tfidf_bi_hyper_1  liar   1.000000  0.523728   0.602317  0.429913   \n",
       "\n",
       "         f1   time              confusion_matrix  \\\n",
       "0  0.857939  34.86        [[385, 89], [64, 462]]   \n",
       "0  0.856884  34.98       [[369, 105], [53, 473]]   \n",
       "0  0.844037   7.72       [[370, 104], [66, 460]]   \n",
       "0  0.841054  15.78       [[362, 112], [63, 463]]   \n",
       "0  0.834114   0.58        [[378, 96], [81, 445]]   \n",
       "0  0.825451   7.16       [[317, 157], [46, 480]]   \n",
       "0  0.823529  12.39       [[280, 194], [22, 504]]   \n",
       "0  0.822430   3.23       [[370, 104], [86, 440]]   \n",
       "0  0.802178   0.30       [[340, 134], [84, 442]]   \n",
       "1  0.839577  34.98       [[396, 107], [60, 437]]   \n",
       "1  0.838583  34.86        [[410, 93], [71, 426]]   \n",
       "1  0.830189  15.78       [[380, 123], [57, 440]]   \n",
       "1  0.829703   0.58        [[409, 94], [78, 419]]   \n",
       "1  0.828516   7.72       [[392, 111], [67, 430]]   \n",
       "1  0.807615   3.23        [[405, 98], [94, 403]]   \n",
       "1  0.800000   0.30       [[370, 133], [77, 420]]   \n",
       "1  0.799641   7.16       [[332, 171], [52, 445]]   \n",
       "1  0.796233  12.39       [[297, 206], [32, 465]]   \n",
       "2  0.674666  12.39  [[1248, 4409], [1258, 5876]]   \n",
       "2  0.625138  15.78  [[2219, 3438], [2327, 4807]]   \n",
       "2  0.617892   7.16  [[2316, 3341], [2451, 4683]]   \n",
       "2  0.592959   7.72  [[2680, 2977], [2873, 4261]]   \n",
       "2  0.578384   0.30  [[2893, 2764], [3107, 4027]]   \n",
       "2  0.575386   0.58  [[2917, 2740], [3146, 3988]]   \n",
       "2  0.536791  34.98  [[3256, 2401], [3636, 3498]]   \n",
       "2  0.521420   3.23  [[3317, 2340], [3793, 3341]]   \n",
       "2  0.501718  34.86  [[3632, 2025], [4067, 3067]]   \n",
       "\n",
       "                                     model  \n",
       "0  LogisticRegression(C=250, max_iter=300)  \n",
       "0  LogisticRegression(C=250, max_iter=300)  \n",
       "0         LogisticRegression(max_iter=300)  \n",
       "0         LogisticRegression(max_iter=300)  \n",
       "0         LogisticRegression(max_iter=300)  \n",
       "0  LogisticRegression(C=0.1, max_iter=300)  \n",
       "0  LogisticRegression(C=0.1, max_iter=300)  \n",
       "0  LogisticRegression(C=250, max_iter=300)  \n",
       "0  LogisticRegression(C=0.1, max_iter=300)  \n",
       "1  LogisticRegression(C=250, max_iter=300)  \n",
       "1  LogisticRegression(C=250, max_iter=300)  \n",
       "1         LogisticRegression(max_iter=300)  \n",
       "1         LogisticRegression(max_iter=300)  \n",
       "1         LogisticRegression(max_iter=300)  \n",
       "1  LogisticRegression(C=250, max_iter=300)  \n",
       "1  LogisticRegression(C=0.1, max_iter=300)  \n",
       "1  LogisticRegression(C=0.1, max_iter=300)  \n",
       "1  LogisticRegression(C=0.1, max_iter=300)  \n",
       "2  LogisticRegression(C=0.1, max_iter=300)  \n",
       "2         LogisticRegression(max_iter=300)  \n",
       "2  LogisticRegression(C=0.1, max_iter=300)  \n",
       "2         LogisticRegression(max_iter=300)  \n",
       "2  LogisticRegression(C=0.1, max_iter=300)  \n",
       "2         LogisticRegression(max_iter=300)  \n",
       "2  LogisticRegression(C=250, max_iter=300)  \n",
       "2  LogisticRegression(C=250, max_iter=300)  \n",
       "2  LogisticRegression(C=250, max_iter=300)  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(mt)\n",
    "\n",
    "info_list = [\n",
    "      (\"../datasets/sample/dataset_unbalanced_10K.csv\", \"content_combined\", mt.create_tdfidf_vector_unigram, [\n",
    "        (LogisticRegression(max_iter=300), \"content_tfidf_bi\"),\n",
    "        (LogisticRegression(max_iter=300, C=250), \"content_tfidf_bi_hyper_1\"),\n",
    "        (LogisticRegression(max_iter=300, C=0.1), \"content_tfidf_bi_hyper_2\")]),\n",
    "     (\"../datasets/sample/dataset_unbalanced_10K.csv\", \"content_combined\", mt.create_tdfidf_vector_bigram, [\n",
    "        (LogisticRegression(max_iter=300), \"content_tfidf_bi\"),\n",
    "        (LogisticRegression(max_iter=300, C=250), \"content_tfidf_bi_hyper_1\"),\n",
    "        (LogisticRegression(max_iter=300, C=0.1), \"content_tfidf_bi_hyper_2\")]),\n",
    "     (\"../datasets/sample/dataset_unbalanced_10K.csv\", \"content_combined\", mt.create_tdfidf_vector_trigram, [\n",
    "        (LogisticRegression(max_iter=300), \"content_tfidf_tri\"),\n",
    "        (LogisticRegression(max_iter=300, C=250), \"content_tfidf_tri_hyper_1\"),\n",
    "        (LogisticRegression(max_iter=300, C=0.1), \"content_tfidf_hyper_2\")]),\n",
    "]\n",
    "\n",
    "test_stats_tdidf_bitri = mt.Test_statistic()\n",
    "\n",
    "mt.create_vectors_from_infolist(\"../datasets/sample/dataset_tdidf_vectors_10K.pickle\", info_list, X_liar, y_liar)\n",
    "mt.test_vectors_from_infolist(\"../datasets/sample/dataset_tdidf_vectors_10K.pickle\", info_list, tests=test_stats_tdidf_bitri)\n",
    "test_stats_tdidf_bitri.metrics.sort_values(by=[\"split\",\"f1\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vector 0 (data read in 108.31220841407776 seconds)\n",
      "Saved vector 0 in 440.462379693985 seconds\n",
      "Creating vector 1 (data read in 106.4322395324707 seconds)\n",
      "Saved vector 1 in 427.0809762477875 seconds\n",
      "Creating vector 2 (data read in 102.18216276168823 seconds)\n",
      "Saved vector 2 in 409.81818413734436 seconds\n",
      "Creating vector 3 (data read in 105.79786205291748 seconds)\n",
      "Saved vector 3 in 438.70478320121765 seconds\n",
      "content_title_count finished in 385.34 seconds\n",
      "content_domain_count finished in 337.14 seconds\n",
      "content_authors_count finished in 335.44 seconds\n",
      "all_count finished in 343.60 seconds\n",
      "all_count_hyper_1 finished in 336.64 seconds\n",
      "all_count_hyper_2 finished in 343.65 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>split</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>acc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all_count_hyper_2</td>\n",
       "      <td>val</td>\n",
       "      <td>0.999620</td>\n",
       "      <td>0.996040</td>\n",
       "      <td>0.996939</td>\n",
       "      <td>0.995444</td>\n",
       "      <td>0.996191</td>\n",
       "      <td>342.35</td>\n",
       "      <td>[[47817, 159], [237, 51787]]</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all_count</td>\n",
       "      <td>val</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.995730</td>\n",
       "      <td>0.996325</td>\n",
       "      <td>0.995464</td>\n",
       "      <td>0.995894</td>\n",
       "      <td>342.31</td>\n",
       "      <td>[[47785, 191], [236, 51788]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all_count_hyper_1</td>\n",
       "      <td>val</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.994480</td>\n",
       "      <td>0.995152</td>\n",
       "      <td>0.994233</td>\n",
       "      <td>0.994692</td>\n",
       "      <td>335.35</td>\n",
       "      <td>[[47724, 252], [300, 51724]]</td>\n",
       "      <td>LogisticRegression(C=250, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content_domain_count</td>\n",
       "      <td>val</td>\n",
       "      <td>0.999764</td>\n",
       "      <td>0.993980</td>\n",
       "      <td>0.994614</td>\n",
       "      <td>0.993811</td>\n",
       "      <td>0.994212</td>\n",
       "      <td>335.69</td>\n",
       "      <td>[[47696, 280], [322, 51702]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content_authors_count</td>\n",
       "      <td>val</td>\n",
       "      <td>0.946640</td>\n",
       "      <td>0.923070</td>\n",
       "      <td>0.938097</td>\n",
       "      <td>0.912329</td>\n",
       "      <td>0.925033</td>\n",
       "      <td>334.12</td>\n",
       "      <td>[[44844, 3132], [4561, 47463]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content_title_count</td>\n",
       "      <td>val</td>\n",
       "      <td>0.911011</td>\n",
       "      <td>0.882290</td>\n",
       "      <td>0.894089</td>\n",
       "      <td>0.877710</td>\n",
       "      <td>0.885824</td>\n",
       "      <td>383.68</td>\n",
       "      <td>[[42567, 5409], [6362, 45662]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all_count_hyper_2</td>\n",
       "      <td>test</td>\n",
       "      <td>0.999620</td>\n",
       "      <td>0.996060</td>\n",
       "      <td>0.996869</td>\n",
       "      <td>0.995615</td>\n",
       "      <td>0.996242</td>\n",
       "      <td>342.35</td>\n",
       "      <td>[[47385, 164], [230, 52221]]</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all_count</td>\n",
       "      <td>test</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.995690</td>\n",
       "      <td>0.996317</td>\n",
       "      <td>0.995462</td>\n",
       "      <td>0.995890</td>\n",
       "      <td>342.31</td>\n",
       "      <td>[[47356, 193], [238, 52213]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all_count_hyper_1</td>\n",
       "      <td>test</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.994520</td>\n",
       "      <td>0.995324</td>\n",
       "      <td>0.994223</td>\n",
       "      <td>0.994773</td>\n",
       "      <td>335.35</td>\n",
       "      <td>[[47304, 245], [303, 52148]]</td>\n",
       "      <td>LogisticRegression(C=250, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content_domain_count</td>\n",
       "      <td>test</td>\n",
       "      <td>0.999764</td>\n",
       "      <td>0.994150</td>\n",
       "      <td>0.995226</td>\n",
       "      <td>0.993613</td>\n",
       "      <td>0.994419</td>\n",
       "      <td>335.69</td>\n",
       "      <td>[[47299, 250], [335, 52116]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content_authors_count</td>\n",
       "      <td>test</td>\n",
       "      <td>0.946640</td>\n",
       "      <td>0.920630</td>\n",
       "      <td>0.937200</td>\n",
       "      <td>0.909630</td>\n",
       "      <td>0.923209</td>\n",
       "      <td>334.12</td>\n",
       "      <td>[[44352, 3197], [4740, 47711]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content_title_count</td>\n",
       "      <td>test</td>\n",
       "      <td>0.911011</td>\n",
       "      <td>0.881610</td>\n",
       "      <td>0.894046</td>\n",
       "      <td>0.878382</td>\n",
       "      <td>0.886145</td>\n",
       "      <td>383.68</td>\n",
       "      <td>[[42089, 5460], [6379, 46072]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content_title_count</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.911011</td>\n",
       "      <td>0.483699</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.267452</td>\n",
       "      <td>0.366219</td>\n",
       "      <td>383.68</td>\n",
       "      <td>[[4279, 1378], [5226, 1908]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content_authors_count</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.946640</td>\n",
       "      <td>0.448988</td>\n",
       "      <td>0.563798</td>\n",
       "      <td>0.053266</td>\n",
       "      <td>0.097336</td>\n",
       "      <td>334.12</td>\n",
       "      <td>[[5363, 294], [6754, 380]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all_count_hyper_1</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.449222</td>\n",
       "      <td>0.604215</td>\n",
       "      <td>0.036165</td>\n",
       "      <td>0.068245</td>\n",
       "      <td>335.35</td>\n",
       "      <td>[[5488, 169], [6876, 258]]</td>\n",
       "      <td>LogisticRegression(C=250, max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content_domain_count</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.999764</td>\n",
       "      <td>0.443280</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.009183</td>\n",
       "      <td>335.69</td>\n",
       "      <td>[[5637, 20], [7101, 33]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all_count</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.442342</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>342.31</td>\n",
       "      <td>[[5643, 14], [7119, 15]]</td>\n",
       "      <td>LogisticRegression(max_iter=300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all_count_hyper_2</td>\n",
       "      <td>liar</td>\n",
       "      <td>0.999620</td>\n",
       "      <td>0.442186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>342.35</td>\n",
       "      <td>[[5656, 1], [7134, 0]]</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=300)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name split  train_acc       acc  precision    recall  \\\n",
       "0      all_count_hyper_2   val   0.999620  0.996040   0.996939  0.995444   \n",
       "0              all_count   val   0.999941  0.995730   0.996325  0.995464   \n",
       "0      all_count_hyper_1   val   0.999982  0.994480   0.995152  0.994233   \n",
       "0   content_domain_count   val   0.999764  0.993980   0.994614  0.993811   \n",
       "0  content_authors_count   val   0.946640  0.923070   0.938097  0.912329   \n",
       "0    content_title_count   val   0.911011  0.882290   0.894089  0.877710   \n",
       "1      all_count_hyper_2  test   0.999620  0.996060   0.996869  0.995615   \n",
       "1              all_count  test   0.999941  0.995690   0.996317  0.995462   \n",
       "1      all_count_hyper_1  test   0.999982  0.994520   0.995324  0.994223   \n",
       "1   content_domain_count  test   0.999764  0.994150   0.995226  0.993613   \n",
       "1  content_authors_count  test   0.946640  0.920630   0.937200  0.909630   \n",
       "1    content_title_count  test   0.911011  0.881610   0.894046  0.878382   \n",
       "2    content_title_count  liar   0.911011  0.483699   0.580645  0.267452   \n",
       "2  content_authors_count  liar   0.946640  0.448988   0.563798  0.053266   \n",
       "2      all_count_hyper_1  liar   0.999982  0.449222   0.604215  0.036165   \n",
       "2   content_domain_count  liar   0.999764  0.443280   0.622642  0.004626   \n",
       "2              all_count  liar   0.999941  0.442342   0.517241  0.002103   \n",
       "2      all_count_hyper_2  liar   0.999620  0.442186   0.000000  0.000000   \n",
       "\n",
       "         f1    time                confusion_matrix  \\\n",
       "0  0.996191  342.35    [[47817, 159], [237, 51787]]   \n",
       "0  0.995894  342.31    [[47785, 191], [236, 51788]]   \n",
       "0  0.994692  335.35    [[47724, 252], [300, 51724]]   \n",
       "0  0.994212  335.69    [[47696, 280], [322, 51702]]   \n",
       "0  0.925033  334.12  [[44844, 3132], [4561, 47463]]   \n",
       "0  0.885824  383.68  [[42567, 5409], [6362, 45662]]   \n",
       "1  0.996242  342.35    [[47385, 164], [230, 52221]]   \n",
       "1  0.995890  342.31    [[47356, 193], [238, 52213]]   \n",
       "1  0.994773  335.35    [[47304, 245], [303, 52148]]   \n",
       "1  0.994419  335.69    [[47299, 250], [335, 52116]]   \n",
       "1  0.923209  334.12  [[44352, 3197], [4740, 47711]]   \n",
       "1  0.886145  383.68  [[42089, 5460], [6379, 46072]]   \n",
       "2  0.366219  383.68    [[4279, 1378], [5226, 1908]]   \n",
       "2  0.097336  334.12      [[5363, 294], [6754, 380]]   \n",
       "2  0.068245  335.35      [[5488, 169], [6876, 258]]   \n",
       "2  0.009183  335.69        [[5637, 20], [7101, 33]]   \n",
       "2  0.004188  342.31        [[5643, 14], [7119, 15]]   \n",
       "2  0.000000  342.35          [[5656, 1], [7134, 0]]   \n",
       "\n",
       "                                     model  \n",
       "0  LogisticRegression(C=0.1, max_iter=300)  \n",
       "0         LogisticRegression(max_iter=300)  \n",
       "0  LogisticRegression(C=250, max_iter=300)  \n",
       "0         LogisticRegression(max_iter=300)  \n",
       "0         LogisticRegression(max_iter=300)  \n",
       "0         LogisticRegression(max_iter=300)  \n",
       "1  LogisticRegression(C=0.1, max_iter=300)  \n",
       "1         LogisticRegression(max_iter=300)  \n",
       "1  LogisticRegression(C=250, max_iter=300)  \n",
       "1         LogisticRegression(max_iter=300)  \n",
       "1         LogisticRegression(max_iter=300)  \n",
       "1         LogisticRegression(max_iter=300)  \n",
       "2         LogisticRegression(max_iter=300)  \n",
       "2         LogisticRegression(max_iter=300)  \n",
       "2  LogisticRegression(C=250, max_iter=300)  \n",
       "2         LogisticRegression(max_iter=300)  \n",
       "2         LogisticRegression(max_iter=300)  \n",
       "2  LogisticRegression(C=0.1, max_iter=300)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(mt)\n",
    "\n",
    "unbalanced = \"../datasets/sample/dataset_unbalanced_1M.csv\"\n",
    "\n",
    "info_list = [\n",
    "    (unbalanced, \"content_title\", mt.create_count_vector, [(LogisticRegression(max_iter=300), \"content_title_count\")]),\n",
    "    (unbalanced, \"content_domain\", mt.create_count_vector, [(LogisticRegression(max_iter=300), \"content_domain_count\")]),\n",
    "    (unbalanced, \"content_authors\", mt.create_count_vector, [(LogisticRegression(max_iter=300), \"content_authors_count\")]),\n",
    "    (unbalanced, \"content_domain_authors_title\", mt.create_count_vector, [(LogisticRegression(max_iter=300), \"all_count\"), \n",
    "                                                                          (LogisticRegression(max_iter=300, C=250), \"all_count_hyper_1\"), \n",
    "                                                                          (LogisticRegression(max_iter=300, C=0.1), \"all_count_hyper_2\")]),\n",
    "]\n",
    "\n",
    "test_stats_meta = mt.Test_statistic()\n",
    "\n",
    "mt.create_vectors_from_infolist(\"../datasets/sample/dataset_count_vectors_meta.pickle\", info_list, X_liar, y_liar)\n",
    "mt.test_vectors_from_infolist(\"../datasets/sample/dataset_count_vectors_meta.pickle\", info_list, tests=test_stats_meta)\n",
    "test_stats_meta.metrics.sort_values(by=[\"split\",\"f1\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"all_count_hyper_1\"\n",
    "\n",
    "#metrics = test_stats_simple.metrics\n",
    "#metrics_test = metrics[metrics[\"split\"] == \"test\"]\n",
    "cm = [[42553, 5423], [7219, 44805]] #metrics_test[metrics_test[\"name\"] == model_name][\"confusion_matrix\"].values[0] * 100\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", xticklabels=[\"Fake\",\"True\"], yticklabels=[\"Fake\",\"True\"], fmt=\"d\", annot_kws={\"size\": 12})\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7134\n",
      "5657\n"
     ]
    }
   ],
   "source": [
    "print(len(y_liar[y_liar == 1]))\n",
    "print(len(y_liar[y_liar == 0]))\n",
    "# calculate f1 score by only predicting 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrlll}\n",
      "\\toprule\n",
      "                        name & split &  train\\_acc &      acc &  precision &   recall &       f1 &  time &             confusion\\_matrix &                                   model \\\\\n",
      "\\midrule\n",
      "                   all\\_count &   val &   1.000000 & 0.915000 &   0.918406 & 0.920152 & 0.919278 &  4.07 &       [[431, 43], [42, 484]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "           all\\_count\\_hyper\\_1 &   val &   1.000000 & 0.907000 &   0.912381 & 0.910646 & 0.911513 &  4.97 &       [[428, 46], [47, 479]] & LogisticRegression(C=250, max\\_iter=300) \\\\\n",
      "           all\\_count\\_hyper\\_2 &   val &   0.997500 & 0.903000 &   0.911708 & 0.903042 & 0.907354 &  2.61 &       [[428, 46], [51, 475]] & LogisticRegression(C=0.1, max\\_iter=300) \\\\\n",
      "        content\\_domain\\_count &   val &   1.000000 & 0.901000 &   0.905123 & 0.906844 & 0.905983 &  3.18 &       [[424, 50], [49, 477]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "       content\\_authors\\_count &   val &   0.999375 & 0.851000 &   0.845872 & 0.876426 & 0.860878 &  4.05 &       [[390, 84], [65, 461]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "            content\\_tfidf\\_bi &   val &   0.965250 & 0.830000 &   0.815603 & 0.874525 & 0.844037 &  8.01 &      [[370, 104], [66, 460]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "           content\\_tfidf\\_tri &   val &   0.978250 & 0.825000 &   0.805217 & 0.880228 & 0.841054 & 16.49 &      [[362, 112], [63, 463]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "               content\\_tfidf &   val &   0.919375 & 0.823000 &   0.822551 & 0.846008 & 0.834114 &  0.56 &       [[378, 96], [81, 445]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "       content\\_tfidf\\_hyper\\_1 &   val &   1.000000 & 0.810000 &   0.808824 & 0.836502 & 0.822430 &  3.55 &      [[370, 104], [86, 440]] & LogisticRegression(C=250, max\\_iter=300) \\\\\n",
      "         content\\_title\\_count &   val &   0.999375 & 0.809000 &   0.820268 & 0.815589 & 0.817922 &  4.24 &       [[380, 94], [97, 429]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "         content\\_count\\_hyper &   val &   0.980500 & 0.807000 &   0.817143 & 0.815589 & 0.816365 &  2.56 &       [[378, 96], [97, 429]] & LogisticRegression(C=0.1, max\\_iter=300) \\\\\n",
      "  content\\_count\\_balanced\\_bin &   val &   0.998125 & 0.803000 &   0.802239 & 0.825336 & 0.813623 &  3.83 &      [[373, 106], [91, 430]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "               content\\_count &   val &   0.998500 & 0.802000 &   0.805970 & 0.821293 & 0.813559 &  5.31 &      [[370, 104], [94, 432]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "       content\\_tfidf\\_hyper\\_2 &   val &   0.838500 & 0.782000 &   0.767361 & 0.840304 & 0.802178 &  0.35 &      [[340, 134], [84, 442]] & LogisticRegression(C=0.1, max\\_iter=300) \\\\\n",
      "content\\_count\\_balanced\\_types &   val &   0.998200 & 0.764000 &   0.862319 & 0.666045 & 0.751579 &  2.31 &      [[407, 57], [179, 357]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      " content\\_count\\_reliable\\_fake &   val &   0.999625 & 0.684000 &   0.753589 & 0.596591 & 0.665962 &  3.46 &     [[369, 103], [213, 315]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "           all\\_count\\_hyper\\_1 &  test &   1.000000 & 0.914000 &   0.911824 & 0.915493 & 0.913655 &  4.97 &       [[459, 44], [42, 455]] & LogisticRegression(C=250, max\\_iter=300) \\\\\n",
      "                   all\\_count &  test &   1.000000 & 0.907000 &   0.908907 & 0.903421 & 0.906155 &  4.07 &       [[458, 45], [48, 449]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "        content\\_domain\\_count &  test &   1.000000 & 0.901000 &   0.899598 & 0.901408 & 0.900503 &  3.18 &       [[453, 50], [49, 448]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "           all\\_count\\_hyper\\_2 &  test &   0.997500 & 0.901000 &   0.904472 & 0.895372 & 0.899899 &  2.61 &       [[456, 47], [52, 445]] & LogisticRegression(C=0.1, max\\_iter=300) \\\\\n",
      "           content\\_tfidf\\_tri &  test &   0.978250 & 0.820000 &   0.781528 & 0.885312 & 0.830189 & 16.49 &      [[380, 123], [57, 440]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "               content\\_tfidf &  test &   0.919375 & 0.828000 &   0.816764 & 0.843058 & 0.829703 &  0.56 &       [[409, 94], [78, 419]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "            content\\_tfidf\\_bi &  test &   0.965250 & 0.822000 &   0.794824 & 0.865191 & 0.828516 &  8.01 &      [[392, 111], [67, 430]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "       content\\_authors\\_count &  test &   0.999375 & 0.819000 &   0.829167 & 0.800805 & 0.814739 &  4.05 &       [[421, 82], [99, 398]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "       content\\_tfidf\\_hyper\\_1 &  test &   1.000000 & 0.808000 &   0.804391 & 0.810865 & 0.807615 &  3.55 &       [[405, 98], [94, 403]] & LogisticRegression(C=250, max\\_iter=300) \\\\\n",
      "               content\\_count &  test &   0.998500 & 0.806000 &   0.808554 & 0.798793 & 0.803644 &  5.31 &      [[409, 94], [100, 397]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "         content\\_count\\_hyper &  test &   0.980500 & 0.807000 &   0.817992 & 0.786720 & 0.802051 &  2.56 &      [[416, 87], [106, 391]] & LogisticRegression(C=0.1, max\\_iter=300) \\\\\n",
      "       content\\_tfidf\\_hyper\\_2 &  test &   0.838500 & 0.790000 &   0.759494 & 0.845070 & 0.800000 &  0.35 &      [[370, 133], [77, 420]] & LogisticRegression(C=0.1, max\\_iter=300) \\\\\n",
      "         content\\_title\\_count &  test &   0.999375 & 0.802000 &   0.804481 & 0.794769 & 0.799595 &  4.24 &      [[407, 96], [102, 395]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "  content\\_count\\_balanced\\_bin &  test &   0.998125 & 0.798000 &   0.804481 & 0.788423 & 0.796371 &  3.83 &      [[403, 96], [106, 395]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "content\\_count\\_balanced\\_types &  test &   0.998200 & 0.775000 &   0.878173 & 0.661568 & 0.754635 &  2.31 &      [[429, 48], [177, 346]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      " content\\_count\\_reliable\\_fake &  test &   0.999625 & 0.695000 &   0.750594 & 0.612403 & 0.674493 &  3.46 &     [[379, 105], [200, 316]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "           content\\_tfidf\\_tri &  liar &   0.978250 & 0.549292 &   0.583020 & 0.673816 & 0.625138 & 16.49 & [[2219, 3438], [2327, 4807]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "            content\\_tfidf\\_bi &  liar &   0.965250 & 0.542647 &   0.588699 & 0.597281 & 0.592959 &  8.01 & [[2680, 2977], [2873, 4261]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "       content\\_tfidf\\_hyper\\_2 &  liar &   0.838500 & 0.541005 &   0.592991 & 0.564480 & 0.578384 &  0.35 & [[2893, 2764], [3107, 4027]] & LogisticRegression(C=0.1, max\\_iter=300) \\\\\n",
      "               content\\_tfidf &  liar &   0.919375 & 0.539833 &   0.592747 & 0.559013 & 0.575386 &  0.56 & [[2917, 2740], [3146, 3988]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "       content\\_tfidf\\_hyper\\_1 &  liar &   1.000000 & 0.520522 &   0.588101 & 0.468321 & 0.521420 &  3.55 & [[3317, 2340], [3793, 3341]] & LogisticRegression(C=250, max\\_iter=300) \\\\\n",
      "               content\\_count &  liar &   0.998500 & 0.480807 &   0.609410 & 0.192459 & 0.292532 &  5.31 &  [[4777, 880], [5761, 1373]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "  content\\_count\\_balanced\\_bin &  liar &   0.998125 & 0.477132 &   0.613544 & 0.168909 & 0.264893 &  3.83 &  [[4898, 759], [5929, 1205]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "         content\\_count\\_hyper &  liar &   0.980500 & 0.475803 &   0.624927 & 0.150407 & 0.242458 &  2.56 &  [[5013, 644], [6061, 1073]] & LogisticRegression(C=0.1, max\\_iter=300) \\\\\n",
      "         content\\_title\\_count &  liar &   0.999375 & 0.474318 &   0.618360 & 0.150126 & 0.241597 &  4.24 &  [[4996, 661], [6063, 1071]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      " content\\_count\\_reliable\\_fake &  liar &   0.999625 & 0.470174 &   0.603358 & 0.146061 & 0.235188 &  3.46 &  [[4972, 685], [6092, 1042]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "       content\\_authors\\_count &  liar &   0.999375 & 0.465093 &   0.627622 & 0.100645 & 0.173472 &  4.05 &   [[5231, 426], [6416, 718]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "content\\_count\\_balanced\\_types &  liar &   0.998200 & 0.462044 &   0.625372 & 0.088450 & 0.154980 &  2.31 &   [[5279, 378], [6503, 631]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "        content\\_domain\\_count &  liar &   1.000000 & 0.448440 &   0.665272 & 0.022288 & 0.043130 &  3.18 &    [[5577, 80], [6975, 159]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "           all\\_count\\_hyper\\_1 &  liar &   1.000000 & 0.446642 &   0.637255 & 0.018223 & 0.035432 &  4.97 &    [[5583, 74], [7004, 130]] & LogisticRegression(C=250, max\\_iter=300) \\\\\n",
      "                   all\\_count &  liar &   1.000000 & 0.445939 &   0.659864 & 0.013597 & 0.026645 &  4.07 &     [[5607, 50], [7037, 97]] &        LogisticRegression(max\\_iter=300) \\\\\n",
      "           all\\_count\\_hyper\\_2 &  liar &   0.997500 & 0.444140 &   0.666667 & 0.006728 & 0.013322 &  2.61 &     [[5633, 24], [7086, 48]] & LogisticRegression(C=0.1, max\\_iter=300) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test_stats_simple.metrics.sort_values(by=[\"split\",\"f1\"], ascending=False).to_latex(index=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning - the best found was C=300 and max_iter=700. The code down below takes around 5 hours to run for 1M entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vector 0 (data read in 2.222195863723755 seconds)\n",
      "Saved vector 0 in 5.955408573150635 seconds\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] END ................................C=200, max_iter=500; total time=   5.0s\n",
      "[CV] END ................................C=200, max_iter=500; total time=   5.8s\n",
      "[CV] END ................................C=200, max_iter=500; total time=   5.3s\n",
      "[CV] END ................................C=250, max_iter=500; total time=   5.8s\n",
      "[CV] END ................................C=250, max_iter=500; total time=   6.0s\n",
      "[CV] END ................................C=250, max_iter=500; total time=   6.1s\n",
      "[CV] END ................................C=300, max_iter=500; total time=   5.4s\n",
      "[CV] END ................................C=300, max_iter=500; total time=   6.5s\n",
      "[CV] END ................................C=300, max_iter=500; total time=   5.8s\n",
      "[CV] END ................................C=350, max_iter=500; total time=   5.4s\n",
      "[CV] END ................................C=350, max_iter=500; total time=   6.6s\n",
      "[CV] END ................................C=350, max_iter=500; total time=   5.9s\n",
      "content_count finished in 77.97 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>split</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>acc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content_count</td>\n",
       "      <td>val</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.783000</td>\n",
       "      <td>0.796545</td>\n",
       "      <td>0.788973</td>\n",
       "      <td>0.792741</td>\n",
       "      <td>77.94</td>\n",
       "      <td>GridSearchCV(cv=3, estimator=LogisticRegressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content_count</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.780287</td>\n",
       "      <td>0.764588</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>77.94</td>\n",
       "      <td>GridSearchCV(cv=3, estimator=LogisticRegressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content_count</td>\n",
       "      <td>liar</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.466891</td>\n",
       "      <td>0.604930</td>\n",
       "      <td>0.127278</td>\n",
       "      <td>0.210307</td>\n",
       "      <td>77.94</td>\n",
       "      <td>GridSearchCV(cv=3, estimator=LogisticRegressio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name split  train_acc       acc  precision    recall        f1  \\\n",
       "0  content_count   val        1.0  0.783000   0.796545  0.788973  0.792741   \n",
       "1  content_count  test        1.0  0.776000   0.780287  0.764588  0.772358   \n",
       "2  content_count  liar        1.0  0.466891   0.604930  0.127278  0.210307   \n",
       "\n",
       "    time                                              model  \n",
       "0  77.94  GridSearchCV(cv=3, estimator=LogisticRegressio...  \n",
       "1  77.94  GridSearchCV(cv=3, estimator=LogisticRegressio...  \n",
       "2  77.94  GridSearchCV(cv=3, estimator=LogisticRegressio...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(mt)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator  = LogisticRegression(),\n",
    "    param_grid = {\"C\": [200, 250, 300, 350], \"max_iter\": [500]},#[500, 600, 700, 800]},\n",
    "    cv         = 3,\n",
    "    scoring    = ['f1'],\n",
    "    refit      = 'f1',\n",
    "    verbose    = 2\n",
    ")\n",
    "\n",
    "unbalanced = \"../datasets/sample/dataset_unbalanced.csv\"\n",
    "\n",
    "info_list = [\n",
    "    (unbalanced, \"content_combined\", mt.create_count_vector, [(grid, \"content_count\")]),\n",
    "]\n",
    "\n",
    "test_stats_hyper_opt = mt.Test_statistic()\n",
    "\n",
    "mt.create_vectors_from_infolist(\"../datasets/sample/hyper_opt.pickle\", info_list, X_liar, y_liar) \n",
    "mt.test_vectors_from_infolist(\"../datasets/sample/hyper_opt.pickle\", info_list, tests=test_stats_hyper_opt)\n",
    "test_stats_hyper_opt.metrics.sort_values(by=\"f1\", ascending=False)\n",
    "# best params\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_files(files, cols_to_test, vec_funcs, tests = None):\n",
    "    if tests == None:\n",
    "        tests = Test_statistic()\n",
    "    for file, name in files:\n",
    "        print(f\"Proccessing: {name}\")\n",
    "        cols_to_read = list(list(zip(*cols_to_test))[0]) + [\"type_binary\", \"set\"]\n",
    "        data = pd.read_csv(file, usecols=cols_to_read)\n",
    "        print(\"Read data into dataframe\")\n",
    "\n",
    "        for col, entry_name in cols_to_test:\n",
    "            for func, model, func_name in vec_funcs:\n",
    "                X_train, X_val, X_test, y_train, y_val, y_test = split_data(data, col, \"type_binary\")\n",
    "                X_train_vec, X_val_vec, X_test_vec = func(X_train, X_val, X_test)\n",
    "                print(f\"Vectorized {entry_name} with {func_name}\")\n",
    "                tests.test_baseline(X_train_vec, X_val_vec, y_train, y_val, name=f\"{entry_name}_{name}_{func_name}\", model=model)\n",
    "    return tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(mt)\n",
    "importlib.reload(pp)\n",
    "\n",
    "def test_on_liar(test, file):\n",
    "    liar_data = pp.apply_pipeline_pd_tqdm(pd.read_csv(file), [(pp.Binary_labels_LIAR(), 'label', 'type_binary')])\n",
    "\n",
    "    metrics = pd.DataFrame()\n",
    "    for row in info_list:\n",
    "        model_name = row[-1]\n",
    "        model = test.metrics[test.metrics[\"name\"] == model_name][\"model\"].values[0]\n",
    "        vectorizer = test.metrics[test.metrics[\"name\"] == model_name][\"vectorizer\"].values[0]\n",
    "        X = vectorizer.transform(liar_data[\"statement_combined\"].values)\n",
    "        #print(liar_data[\"type_binary\"].astype(int).value_counts())\n",
    "        metrics = pd.concat([mt.get_predict_metrics(model, X, liar_data[\"type_binary\"].astype(int), name=model_name), metrics])\n",
    "\n",
    "        \n",
    "    return metrics.sort_values(by=\"f1\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ../datasets/sample/dataset_unbalanced_cleaned.csv ----------------------------------\n",
      "Distribution of train with size 4000:\n",
      "fake: 0.12475, conspiracy: 0.112, junksci: 0.0165, hate: 0.01025, unreliable: 0.03825, bias: 0.15625, satire: 0.01725, reliable: 0.257, clickbait: 0.03075, political: 0.237\n",
      "True: 2099, Fake: 1901\n",
      "Distribution of val with size 500:\n",
      "fake: 0.108, conspiracy: 0.098, junksci: 0.01, hate: 0.008, unreliable: 0.044, bias: 0.174, satire: 0.01, reliable: 0.25, clickbait: 0.044, political: 0.254\n",
      "True: 274, Fake: 226\n",
      "Distribution of test with size 500:\n",
      "fake: 0.134, conspiracy: 0.128, junksci: 0.026, hate: 0.01, unreliable: 0.056, bias: 0.134, satire: 0.012, reliable: 0.244, clickbait: 0.034, political: 0.222\n",
      "True: 250, Fake: 250\n",
      "File: ../datasets/sample/dataset_balanced_types_cleaned.csv ----------------------------------\n",
      "Distribution of train with size 4000:\n",
      "fake: 0.1, conspiracy: 0.1, junksci: 0.1, hate: 0.1, unreliable: 0.1, bias: 0.1, satire: 0.1, reliable: 0.1, clickbait: 0.1, political: 0.1\n",
      "True: 1200, Fake: 2800\n",
      "Distribution of val with size 500:\n",
      "fake: 0.108, conspiracy: 0.112, junksci: 0.006, hate: 0.008, unreliable: 0.05, bias: 0.166, satire: 0.014, reliable: 0.27, clickbait: 0.026, political: 0.24\n",
      "True: 268, Fake: 232\n",
      "Distribution of test with size 500:\n",
      "fake: 0.132, conspiracy: 0.096, junksci: 0.014, hate: 0.01, unreliable: 0.044, bias: 0.158, satire: 0.01, reliable: 0.244, clickbait: 0.022, political: 0.27\n",
      "True: 268, Fake: 232\n",
      "File: ../datasets/sample/dataset_balanced_bin_cleaned.csv ----------------------------------\n",
      "Distribution of train with size 4000:\n",
      "fake: 0.13175, conspiracy: 0.11775, junksci: 0.017, hate: 0.0105, unreliable: 0.0405, bias: 0.165, satire: 0.0175, reliable: 0.18275, clickbait: 0.022, political: 0.16425\n",
      "True: 2000, Fake: 2000\n",
      "Distribution of val with size 500:\n",
      "fake: 0.088, conspiracy: 0.088, junksci: 0.016, hate: 0.008, unreliable: 0.034, bias: 0.138, satire: 0.014, reliable: 0.22, clickbait: 0.038, political: 0.202\n",
      "True: 307, Fake: 193\n",
      "Distribution of test with size 500:\n",
      "fake: 0.122, conspiracy: 0.096, junksci: 0.016, hate: 0.008, unreliable: 0.05, bias: 0.116, satire: 0.006, reliable: 0.214, clickbait: 0.026, political: 0.202\n",
      "True: 293, Fake: 207\n",
      "File: ../datasets/sample/dataset_reliable_fake_cleaned.csv ----------------------------------\n",
      "Distribution of train with size 4000:\n",
      "fake: 0.5, conspiracy: 0.0, junksci: 0.0, hate: 0.0, unreliable: 0.0, bias: 0.0, satire: 0.0, reliable: 0.5, clickbait: 0.0, political: 0.0\n",
      "True: 2000, Fake: 2000\n",
      "Distribution of val with size 500:\n",
      "fake: 0.306, conspiracy: 0.0, junksci: 0.0, hate: 0.0, unreliable: 0.0, bias: 0.0, satire: 0.0, reliable: 0.694, clickbait: 0.0, political: 0.0\n",
      "True: 347, Fake: 153\n",
      "Distribution of test with size 500:\n",
      "fake: 0.302, conspiracy: 0.0, junksci: 0.0, hate: 0.0, unreliable: 0.0, bias: 0.0, satire: 0.0, reliable: 0.698, clickbait: 0.0, political: 0.0\n",
      "True: 349, Fake: 151\n"
     ]
    }
   ],
   "source": [
    "def get_distribution(data, is_percentage=True, col = \"type\"):\n",
    "    for i, label in enumerate(pp.labels):\n",
    "        if is_percentage:\n",
    "            percent = len(data[data[col] == label]) / (data.shape[0])\n",
    "        else:\n",
    "            percent = len(data[data[col] == label])\n",
    "        print(f\"{label}: {percent}\", end=\"\")\n",
    "        print(\", \", end=\"\") if i != len(pp.labels) - 1 else _\n",
    "\n",
    "unbalanced = \"../datasets/sample/dataset_unbalanced_cleaned.csv\"\n",
    "balanced_types = \"../datasets/sample/dataset_balanced_types_cleaned.csv\"\n",
    "balanced_bin = \"../datasets/sample/dataset_balanced_bin_cleaned.csv\"\n",
    "balanced_reliable_fake = \"../datasets/sample/dataset_reliable_fake_cleaned.csv\"\n",
    "\n",
    "for file in [unbalanced, balanced_types, balanced_bin, balanced_reliable_fake]:\n",
    "    data = pd.read_csv(file)\n",
    "    print(f\"File: {file} ----------------------------------\")\n",
    "    # find distribution of labels\n",
    "    for i, set_name in enumerate([\"train\", \"val\", \"test\"]):\n",
    "        set = data[data[\"set\"] == i]\n",
    "        print(f\"Distribution of {set_name} with size {set.shape[0]}:\")\n",
    "        get_distribution(set)\n",
    "        print(f\"\\nTrue: {len(set[set['type_binary'] == True])}, Fake: {len(set[set['type_binary'] == False])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penguin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
